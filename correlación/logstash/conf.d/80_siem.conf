# Fichero 80_siem.conf
#
#Eventos normalizados 

filter {
  if [@metadata][siem_data_type] == "normalizedEvent" {
    uuid {
      target    => "event_id"
      overwrite => true
    }
  }
}
# Se comprueba si es un evento normalizado, y en el caso de que lo sea se envía al motor de correlación de Dsiem y a Elasticsearch para su almacenamiento

output{
  if [@metadata][siem_data_type] == "normalizedEvent" {
    http {
      format=>"json"
      http_method=>"post"
      url=>"http://0.0.0.0:8080/events"
    }

    elasticsearch {
      hosts => "192.168.56.2:9200"
      index => "siem_events-%{+YYYY.MM.dd}"
      document_id => "%{[event_id]}"
      action => "index"
      template => "/etc/logstash/index-template.d/siem_events-template.json"
      template_name => "siem_events"
      template_overwrite => true
    }
  }
}

# Alarmas y eventos recogidos por la segunda instancia de Filebeat
# Se añaden campos de metadatos y se eliminan los campos no necesarios

filter {
  if [siem_data_type] == "alarm_events" {
    mutate {
      add_field => {
        "[@metadata][siem_data_type]" => "alarm_events"
      }
    }
    prune {
	 whitelist_names => [ "@metadata", "@timestamp", "alarm_id",  "event_id", "stage" ]
    }
  }

  if [siem_data_type] == "alarms" {
    date {
      match => [ "created_time", "UNIX" ]
      target => "timestamp"
    }
    date {
      match => [ "update_time", "UNIX" ]
      target => "updated_time"
    }
    mutate {
      add_field => {
              "[@metadata][alarm_id]" => "%{[alarm_id]}"
              "[@metadata][siem_data_type]" => "alarms"
      }
    }

# Búsqueda en Elasticsearch con un ID determinado (perm index)
# La búsqueda se realiza a través del alias siem_alarms_id_lookup, el cual se asigna por defecto a todos los índices cuando se crean
    

elasticsearch {
      hosts => ["192.168.56.2:9200"]
      index => "siem_alarms_id_lookup"
      query => "_id:%{[alarm_id]}"
      fields => {
        "perm_index" => "[@metadata][target_index]"
        }
    }

# Si el paso anterior no devuelve ningún resultado, se utiliza la fecha actual 

    if ![@metadata][target_index] {
      mutate {
        add_field => {
          "[@metadata][target_index]" => "siem_alarms-%{+YYYY.MM.dd}"
        }
      }
    }

# Se añade este campo para que elasticsearch no busque únicamente según el campo _source 

    mutate {
      add_field => {
        "perm_index" => "%{[@metadata][target_index]}"
      }
   }
    prune {
      whitelist_names => [ "timestamp", "@metadata", "title", "status",   
      "kingdom", "category", "updated_time", "risk", "risk_class",
      "tag$", "src_ips", "dst_ips", "intel_hits", "vulnerabilities",
      "networks", "rules", "custom_data", "^perm_index$" ]
    }
  }
}

# Si los datos son eventos normalizados asociados a alarmas, se almacenan en el índice correspondiente de Elasticsearch

output {
  if [@metadata][siem_data_type] == "alarm_events" {
    elasticsearch {
      hosts => "192.168.56.2:9200"
      index => "siem_alarm_events-%{+YYYY.MM.dd}"
      template => "/etc/logstash/index-template.d/siem_alarm_events-
      template.json"
      template_name => "siem_alarm_events"
      template_overwrite => true
    }
  }

#Se utiliza doc_as_upsert para poder actualizar las alarmas una vez almacenadas (actualización de status o tag)

  if [@metadata][siem_data_type] == "alarms" {

    elasticsearch {
      hosts => "192.168.56.2:9200"
      index => "%{[@metadata][target_index]}"
      document_id => "%{[@metadata][alarm_id]}"
      template => "/etc/logstash/index-template.d/siem_alarms-template.json"
      template_name => "siem_alarms"
      template_overwrite => true
      action => "update"
      # Se comprueba el riesgo de la nueva alarma actualizada, y se actualiza dicha alarma si el riesgo es mayor que el que ya estaba almacenado
      
      doc_as_upsert => true
                        script_lang => "painless"
                        script_type => "inline"
      

script => '
  int incoming_risk = params.event.get("risk");
  int existing_risk = ctx._source.risk;

  if (incoming_risk < existing_risk) {
   ctx.op = "none";
   return
  } 
  else if (incoming_risk == existing_risk) {
   ZonedDateTime old_tm = ZonedDateTime.parse(ctx._source.updated_time);
   ZonedDateTime new_tm = ZonedDateTime.parse(params.event.get("updated_time”)


  if (new_tm.isBefore(old_tm)) {
   ctx.op = "none";
   return
  }
  }
  ctx._source.timestamp = params.event.get("timestamp");
  ctx._source.updated_time = params.event.get("updated_time");
  ctx._source.risk = incoming_risk;
  ctx._source.risk_class = params.event.get("risk_class");
  ctx._source.src_ips = params.event.get("src_ips");
  ctx._source.dst_ips = params.event.get("dst_ips");
  ctx._source.rules = params.event.get("rules");
  ctx._source.networks = params.event.get("networks");

  if (params.event.get("intel_hits") != null) {
   ctx._source.intel_hits = params.event.get("intel_hits")
  }

  if (params.event.get("vulnerabilities") != null) {
   ctx._source.vulnerabilities = params.event.get("vulnerabilities")
  }

  if (params.event.get("custom_data") != null) {
   ctx._source.custom_data = params.event.get("custom_data")
  }
  '
  retry_on_conflict => 5
   }
  }
}
